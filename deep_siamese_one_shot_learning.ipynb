{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep-siamese-one-shot-learning",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/DongminWu/MLpractice/blob/master/deep_siamese_one_shot_learning.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "yIBfYkgp95Xg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from scipy.stats import norm\n",
        "\n",
        "from scipy.signal import triang\n",
        "\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xXZm30OPEpA1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Generating"
      ]
    },
    {
      "metadata": {
        "id": "L2cICGsSFx76",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_of_each_type = 40\n",
        "num_of_weekend = 13\n",
        "day_length = 1440"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rNXs8eLAC-AV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gaussian_pdf(mu,  sigma, length):\n",
        "  '''\n",
        "  mu: mean of the gaussian distribution\n",
        "  sigma: variance of the gaussian distribution\n",
        "  \n",
        "  length: the length of the sequence\n",
        "  '''\n",
        "  \n",
        "  raw_ = np.linspace(-5, 5, length)\n",
        "  ret = 1/(sigma * np.sqrt(2 * np.pi)) * \\\n",
        "      np.exp( - (raw_ - mu)**2 / (2 * sigma**2))\n",
        "  return ret\n",
        "\n",
        "                \n",
        "  \n",
        "\n",
        "# Triangle wave\n",
        "\n",
        "def triangle_pdf(mid, width, length):\n",
        "\n",
        "  raw_ = np.linspace(-5, 5, length)\n",
        "\n",
        "  l_mask = mid  - float(width)/2\n",
        "  l_empty = np.where(raw_ < l_mask)[0]\n",
        "\n",
        "  ret_l = [0]*len(l_empty)\n",
        "\n",
        "  r_mask = mid + float(width)/2\n",
        "  r_empty = np.where(raw_ > r_mask)[0]\n",
        "  ret_r = [0]*len(r_empty)\n",
        "\n",
        "  number_mid = length - len(l_empty) - len(r_empty)\n",
        "  ret_m = triang(number_mid)\n",
        "\n",
        "  ret = np.concatenate([ret_l, ret_m, ret_r])\n",
        "  \n",
        "  return ret\n",
        "\n",
        "\n",
        "def random_pdf(prob, max, length):\n",
        "  raw = [0] * length\n",
        "  \n",
        "  for i,each in enumerate(raw):\n",
        "    r = np.random.random()\n",
        "    if r < prob:\n",
        "      raw[i] = np.random.uniform(-max, max)\n",
        "\n",
        "  return np.array(raw)\n",
        "\n",
        "\n",
        "def generate_binary(distribution):\n",
        "  return np.array([np.random.choice( np.array([0,1]),p=[1-p,p]) for p in distribution])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jnRQjwYk8aO1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train set"
      ]
    },
    {
      "metadata": {
        "id": "RjzE5hJVEoR1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 4 sensors\n",
        "\n",
        "g1_set = [generate_binary(gaussian_pdf(0,1,day_length)) for i in range(num_of_each_type)]\n",
        "g2_set = [generate_binary(gaussian_pdf(1,1.3,day_length)) for i in range(num_of_each_type)]\n",
        "t1_set = [generate_binary(triangle_pdf(0,5,day_length)) for i in range(num_of_each_type)]\n",
        "t2_set = [generate_binary(triangle_pdf(-1,4,day_length)) for i in range(num_of_each_type)]\n",
        "empty1_set = [generate_binary(np.clip(random_pdf(0.1, 0.2, day_length),0,1)) for i in range(num_of_weekend)]\n",
        "empty2_set = [generate_binary(np.clip(random_pdf(0.1, 0.2, day_length),0,1)) for i in range(num_of_weekend)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OuVjUqZSF0xu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e03da97e-08f8-4988-895c-ee88d0492ffd"
      },
      "cell_type": "code",
      "source": [
        "g_set = np.concatenate([g1_set, g2_set])\n",
        "np.random.shuffle(g_set)\n",
        "g_pair_set = g_set.reshape([-1,2,1440])\n",
        "\n",
        "t_set = np.concatenate([t1_set, t2_set])\n",
        "np.random.shuffle(t_set)\n",
        "t_pair_set = t_set.reshape([-1,2,1440])\n",
        "\n",
        "empty_set = np.concatenate([empty1_set, empty2_set])\n",
        "np.random.shuffle(empty_set)\n",
        "empty_pair_set = empty_set.reshape([-1,2,1440])\n",
        "\n",
        "trainX_neighbors = np.concatenate([g_pair_set, t_pair_set, empty_pair_set])\n",
        "trainY_neighbors = np.ones([trainX_neighbors.shape[0],1])\n",
        "\n",
        "print(\"trainX_neighbors\", trainX_neighbors.shape)\n",
        "print(\"trainY_neighbors\", trainY_neighbors.shape)\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('trainX_neighbors', (93, 2, 1440))\n",
            "('trainY_neighbors', (93, 1))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AwJyOpXmKI_A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "df40fc8f-ddcf-4506-9c3b-6dac0ba1ec77"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "trainX_no_neighbors = []\n",
        "for i in range(trainX_neighbors.shape[0]):\n",
        "  first_set = np.random.choice([t_set, g_set, empty_set])\n",
        "  second_set = np.random.choice([t_set, g_set, empty_set])\n",
        "  first_idx = np.random.choice(first_set.shape[0]-1)\n",
        "  second_idx = np.random.choice(second_set.shape[0]-1)\n",
        "  sample = np.array([first_set[first_idx], second_set[second_idx]] )\n",
        "  trainX_no_neighbors.append(sample)\n",
        "\n",
        "trainX_no_neighbors = np.stack(trainX_no_neighbors)\n",
        "trainY_no_neighbors = np.ones([trainX_no_neighbors.shape[0],1])\n",
        "print(\"trainX_no_neighbors\", trainX_no_neighbors.shape)\n",
        "print(\"trainY_no_neighbors\", trainY_no_neighbors.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('trainX_no_neighbors', (93, 2, 1440))\n",
            "('trainY_no_neighbors', (93, 1))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K5wviVShd8jZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5cfb9a78-de91-461c-ccc9-4ca340b93830"
      },
      "cell_type": "code",
      "source": [
        "trainX = np.concatenate([trainX_neighbors, trainX_no_neighbors])\n",
        "trainY = np.concatenate([trainY_neighbors, trainY_no_neighbors])\n",
        "trainX, trainY = shuffle(trainX, trainY)\n",
        "print(\"trainX\", trainX.shape)\n",
        "print(\"trainY\", trainY.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('trainX', (186, 2, 1440))\n",
            "('trainY', (186, 1))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4b5P3vW_8c56",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test Set\n",
        "\n",
        "The difference is the mean and variance of each waveform\n"
      ]
    },
    {
      "metadata": {
        "id": "yHUW7d5KLcwS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d60f5c99-a807-4385-b416-bc51821add9a"
      },
      "cell_type": "code",
      "source": [
        "# 4 sensors\n",
        "\n",
        "g1_set = [generate_binary(gaussian_pdf(0.5,1.2,day_length)) for i in range(num_of_each_type)]\n",
        "g2_set = [generate_binary(gaussian_pdf(-0.3,1.9,day_length)) for i in range(num_of_each_type)]\n",
        "t1_set = [generate_binary(triangle_pdf(0,3,day_length)) for i in range(num_of_each_type)]\n",
        "t2_set = [generate_binary(triangle_pdf(-2,3,day_length)) for i in range(num_of_each_type)]\n",
        "empty1_set = [generate_binary(np.clip(random_pdf(0.1, 0.2, day_length),0,1)) for i in range(num_of_weekend)]\n",
        "empty2_set = [generate_binary(np.clip(random_pdf(0.1, 0.2, day_length),0,1)) for i in range(num_of_weekend)]\n",
        "\n",
        "g_set = np.concatenate([g1_set, g2_set])\n",
        "np.random.shuffle(g_set)\n",
        "g_pair_set = g_set.reshape([-1,2,1440])\n",
        "\n",
        "t_set = np.concatenate([t1_set, t2_set])\n",
        "np.random.shuffle(t_set)\n",
        "t_pair_set = t_set.reshape([-1,2,1440])\n",
        "\n",
        "empty_set = np.concatenate([empty1_set, empty2_set])\n",
        "np.random.shuffle(empty_set)\n",
        "empty_pair_set = empty_set.reshape([-1,2,1440])\n",
        "\n",
        "testX_neighbors = np.concatenate([g_pair_set, t_pair_set, empty_pair_set])\n",
        "testY_neighbors = np.ones([testX_neighbors.shape[0],1])\n",
        "\n",
        "print(\"testX_neighbors\", testX_neighbors.shape)\n",
        "print(\"testY_neighbors\", testY_neighbors.shape)\n",
        "\n",
        "testX_no_neighbors = []\n",
        "for i in range(testX_neighbors.shape[0]):\n",
        "  first_set = np.random.choice([t_set, g_set, empty_set])\n",
        "  second_set = np.random.choice([t_set, g_set, empty_set])\n",
        "  first_idx = np.random.choice(first_set.shape[0]-1)\n",
        "  second_idx = np.random.choice(second_set.shape[0]-1)\n",
        "  sample = np.array([first_set[first_idx], second_set[second_idx]] )\n",
        "  testX_no_neighbors.append(sample)\n",
        "\n",
        "testX_no_neighbors = np.stack(testX_no_neighbors)\n",
        "testY_no_neighbors = np.ones([testX_no_neighbors.shape[0],1])\n",
        "print(\"testX_no_neighbors\", testX_no_neighbors.shape)\n",
        "print(\"testY_no_neighbors\", testY_no_neighbors.shape)\n",
        "\n",
        "\n",
        "testX = np.concatenate([testX_neighbors, testX_no_neighbors])\n",
        "testY = np.concatenate([testY_neighbors, testY_no_neighbors])\n",
        "testX, testY = shuffle(testX, testY)\n",
        "print(\"testX\", testX.shape)\n",
        "print(\"testY\", testY.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('testX_neighbors', (93, 2, 1440))\n",
            "('testY_neighbors', (93, 1))\n",
            "('testX_no_neighbors', (93, 2, 1440))\n",
            "('testY_no_neighbors', (93, 1))\n",
            "('testX', (186, 2, 1440))\n",
            "('testY', (186, 1))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iLERZXbBJ7aG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# model building\n",
        "\n",
        "![替代文字](https://cloud.githubusercontent.com/assets/9861437/20479454/405a1aea-b004-11e6-8a27-7bb05cf0a002.png)"
      ]
    },
    {
      "metadata": {
        "id": "-6uvuDNwRpKU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras import Model\n",
        "from keras.layers import LSTM, Bidirectional, Input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X-KCg6Trk01W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dim_lstm_layer = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YiqVOiLHLe3F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input1 = Input(shape=(None, 1), name = 'input_layer1')\n",
        "input2 = Input(shape=(None, 1), name = 'input_layer2')\n",
        "\n",
        "bi_lstm1_1 = Bidirectional(LSTM(dim_lstm_layer, return_sequences=True, name=\"LSTM_layer1_1\"))(input1)\n",
        "bi_lstm1_2 = Bidirectional(LSTM(dim_lstm_layer, return_sequences=True, name=\"LSTM_layer1_2\"))(input2)\n",
        "\n",
        "bi_lstm2_1 = Bidirectional(LSTM(dim_lstm_layer, return_sequences=True, name=\"LSTM_layer2_1\"))(bi_lstm1_1)\n",
        "bi_lstm2_2 = Bidirectional(LSTM(dim_lstm_layer, return_sequences=True, name=\"LSTM_layer2_2\"))(bi_lstm1_2)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i5-6oIX_lOm4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}